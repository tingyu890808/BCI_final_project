# -*- coding: utf-8 -*-
"""k fold erp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MBAM5coxOM3YyYy_TS_1S7i7l9Pyi6S0
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from google.colab import drive
import numpy as np 
import h5py
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt
import matplotlib as mpl

f1 = h5py.File("observer_all.mat")
f2 = h5py.File("player_all.mat")

v1 = f1['observer']
v2 = f2['player']
observer = np.array(v1)
player = np.array(v2)

all = np.concatenate((player, observer), axis=1)

X = np.transpose(all)
print(X.shape)
y1 = np.zeros([1,58])
y2 = np.ones([1,58])
y = np.concatenate((y1, y2), axis=1)
y = np.transpose(y)
print(y.shape)

import numpy as np
import copy as cp
import matplotlib.pyplot as plt

import seaborn as sns
from typing import Tuple
from sklearn.metrics import confusion_matrix

def cross_val_predict(model, kfold : KFold, X : np.array, y : np.array) -> Tuple[np.array, np.array, np.array]:

    model_ = cp.deepcopy(model)
    
    no_classes = len(np.unique(y))
    
    actual_classes = np.empty([0], dtype=int)
    predicted_classes = np.empty([0], dtype=int)
    predicted_proba = np.empty([0, no_classes]) 

    for train_ndx, test_ndx in kfold.split(X):

        train_X, train_y, test_X, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx]

        actual_classes = np.append(actual_classes, test_y)

        model_.fit(train_X, train_y)
        predicted_classes = np.append(predicted_classes, model_.predict(test_X))


        try:
            predicted_proba = np.append(predicted_proba, model_.predict_proba(test_X), axis=0)
        except:
            predicted_proba = np.append(predicted_proba, np.zeros((len(test_X), no_classes), dtype=float), axis=0)

    return actual_classes, predicted_classes, predicted_proba

def plot_confusion_matrix(actual_classes : np.array, predicted_classes : np.array, sorted_labels : list):

    matrix = confusion_matrix(actual_classes, predicted_classes, labels=sorted_labels)
    
    plt.figure(figsize=(12.8,6))
    sns.heatmap(matrix, annot=True, xticklabels=sorted_labels, yticklabels=sorted_labels, cmap="Blues", fmt="g")
    plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')

    plt.show()

from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.cm as cm
import matplotlib.colors as mcolors

LDA = LinearDiscriminantAnalysis()
model = LDA

kfold = KFold(n_splits=10, shuffle=True)

actual = np.empty([0], dtype=int)
predicted = np.empty([0], dtype=int)
sum_confusion_matrix = None
k = 10
for i in range(10):
    actual_classes, predicted_classes, _ = cross_val_predict(model, kfold,X, np.ravel(y,order = 'C'))
    fold_confusion_matrix = confusion_matrix(actual_classes,predicted_classes)
    if sum_confusion_matrix is None:
        sum_confusion_matrix = fold_confusion_matrix
    else:
        sum_confusion_matrix += fold_confusion_matrix


mean_confusion_matrix = sum_confusion_matrix / k


plt.figure(figsize=(12.8,6))
sns.heatmap(mean_confusion_matrix, annot=True, cmap="Blues", fmt="g")
plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')

plt.show()


scores = cross_val_score(model, X, np.ravel(y,order='C'), cv=10)
average_score = scores.mean()
print(f"Average score: {average_score} +/- {np.std(scores)}")
#print("Mean Confusion Matrix:")
# plot_confusion_matrix(actual_classes, predicted_classes,[0,1])
#print(classification_report(actual_classes,predicted_classes))

from sklearn import  ensemble, preprocessing, metrics
from sklearn.ensemble import AdaBoostClassifier

abc = AdaBoostClassifier(n_estimators=100, random_state = 42)
model = abc

kfold = KFold(n_splits=10, shuffle=True)

actual = np.empty([0], dtype=int)
predicted = np.empty([0], dtype=int)
sum_confusion_matrix = None
k = 10
for i in range(10):
    actual_classes, predicted_classes, _ = cross_val_predict(model, kfold,X, np.ravel(y,order = 'C'))
    fold_confusion_matrix = confusion_matrix(actual_classes,predicted_classes)
    if sum_confusion_matrix is None:
        sum_confusion_matrix = fold_confusion_matrix
    else:
        sum_confusion_matrix += fold_confusion_matrix


mean_confusion_matrix = sum_confusion_matrix / k


plt.figure(figsize=(12.8,6))
sns.heatmap(mean_confusion_matrix, annot=True, cmap="Blues", fmt="g")
plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')

plt.show()

scores = cross_val_score(model, X, np.ravel(y,order='C'), cv=10)
average_score = scores.mean()
print(f"Average score: {average_score} +/- {np.std(scores)}")

from sklearn.ensemble import BaggingClassifier
from sklearn.metrics import classification_report, confusion_matrix

bagging=BaggingClassifier(n_estimators=100,random_state = 42)
model = bagging

actual = np.empty([0], dtype=int)
predicted = np.empty([0], dtype=int)
sum_confusion_matrix = None
k = 10
for i in range(10):
    actual_classes, predicted_classes, _ = cross_val_predict(model, kfold,X, np.ravel(y,order = 'C'))
    fold_confusion_matrix = confusion_matrix(actual_classes,predicted_classes)
    if sum_confusion_matrix is None:
        sum_confusion_matrix = fold_confusion_matrix
    else:
        sum_confusion_matrix += fold_confusion_matrix


mean_confusion_matrix = sum_confusion_matrix / k

plt.figure(figsize=(12.8,6))
sns.heatmap(mean_confusion_matrix, annot=True, cmap="Blues", fmt="g")
plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')

plt.show()

scores = cross_val_score(model, X, np.ravel(y,order='C'), cv=10)
average_score = scores.mean()
print(f"Average score: {average_score} +/- {np.std(scores)}")

from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt

pipeline = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100, random_state = 42))

model = pipeline

actual = np.empty([0], dtype=int)
predicted = np.empty([0], dtype=int)
sum_confusion_matrix = None
k = 10
for i in range(10):
    actual_classes, predicted_classes, _ = cross_val_predict(model, kfold,X, np.ravel(y,order = 'C'))
    fold_confusion_matrix = confusion_matrix(actual_classes,predicted_classes)
    if sum_confusion_matrix is None:
        sum_confusion_matrix = fold_confusion_matrix
    else:
        sum_confusion_matrix += fold_confusion_matrix


mean_confusion_matrix = sum_confusion_matrix / k


plt.figure(figsize=(12.8,6))
sns.heatmap(mean_confusion_matrix, annot=True, cmap="Blues", fmt="g")
plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')

plt.show()

scores = cross_val_score(model, X, np.ravel(y,order='C'), cv=10)
average_score = scores.mean()
print(f"Average score: {average_score} +/- {np.std(scores)}")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.svm import SVC, SVR
from sklearn.metrics import accuracy_score

def cross_validation(X_train, shuffle=True, k=5, random_state=35):
    n_samples = X_train.shape[0]
    indices = np.arange(n_samples)
    if shuffle:
        rstate = np.random.RandomState(random_state)
        rstate.shuffle(indices)
    n_splits = k
    fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=int)
    fold_sizes[: n_samples % n_splits] += 1
    KFold = []
    current = 0
    for fold_size in fold_sizes:
        start, stop = current, current + fold_size
        
        # get_test_mask function content merged into cross_validation
        test_index = indices[start:stop]
        test_mask = np.zeros(n_samples, dtype=bool)
        test_mask[test_index] = True
        
        train_index = indices[np.logical_not(test_mask)]
        test_index = indices[test_mask]
        # error = [x for x in train_index if x in test_index]
        # print(len(error))
        KFold.append([train_index, test_index])
        current = stop
    return KFold

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state = 42)
kfold_data = cross_validation(X_train, k=5)
assert len(kfold_data) == 5 # should contain 10 fold of data
assert len(kfold_data[0]) == 2 # each element should contain train fold and validation fold
#assert kfold_data[0][1].shape[0] == 700 # The number of data in each validation fold should equal to training data divieded by K

def gridsearch(x, y, kfold_data, candidate_C, candidate_gamma):
    history = []
    max_acc = 0
    n_gamma = len(candidate_gamma)
    candidate = [(c, g) for c in candidate_C for g in candidate_gamma]
    tmp_acc = []

    for i, (c, g) in enumerate(candidate):
        avg_acc = 0

        for j, (train, test) in enumerate(kfold_data):
            clf = SVC(C=c, kernel='rbf', gamma=g)
            clf.fit(x[train], np.ravel(y[train],order = 'C'))
            y_pred = clf.predict(x[test])
            acc = accuracy_score(y[test], np.ravel(y_pred,order = 'C'))
            avg_acc += acc

        avg_acc /= len(kfold_data)
        tmp_acc.append(avg_acc)
        
        if avg_acc > max_acc:
            best_C = c
            best_gamma = g
            max_acc = avg_acc

        if (i + 1) % n_gamma == 0:
            history.append(tmp_acc)
            tmp_acc = []

    return np.asarray(history), (best_C, best_gamma)

candidate_C = np.logspace(-4, 4, num=9)
candidate_gamma = np.logspace(-4, 4, num=9)
history, best_parameters = gridsearch(X_train, y_train, kfold_data, candidate_C, candidate_gamma)
print(f'Best parameters (C, gamma): {best_parameters}')

print(f'Best parameters (C, gamma): {best_parameters}')

candidate_C = np.logspace(-4, 4, num= 9)
candidate_gamma = np.logspace(-4, 4, num= 9)
print(candidate_C)
print(candidate_gamma)

from matplotlib.colors import LinearSegmentedColormap
cmap = LinearSegmentedColormap.from_list("custom", ["red", "white", "blue"])

plt.imshow(history, cmap= cmap)
plt.colorbar()

for i in range(history.shape[0]):
    for j in range(history.shape[1]):
        plt.text(j, i, f"{history[i, j]:.2f}", ha="center", va="center", color="black" if history[i, j] < 0.6 else "white")
plt.ylabel("C")
plt.xlabel("Gamma")
plt.yticks(np.arange(9), candidate_C, rotation = 45)
plt.xticks(np.arange(9), candidate_gamma, rotation = 45)
plt.show()

best_model = SVC(C=best_parameters[0], gamma=best_parameters[1], kernel='rbf')
best_model.fit(X_train, y_train)

y_pred = best_model.predict(X_test)

print("Accuracy score: ", accuracy_score(y_pred, y_test))

model = best_model

actual = np.empty([0], dtype=int)
predicted = np.empty([0], dtype=int)
sum_confusion_matrix = None
k = 10
for i in range(10):
    actual_classes, predicted_classes, _ = cross_val_predict(model, kfold,X, np.ravel(y,order = 'C'))
    fold_confusion_matrix = confusion_matrix(actual_classes,predicted_classes)
    if sum_confusion_matrix is None:
        sum_confusion_matrix = fold_confusion_matrix
    else:
        sum_confusion_matrix += fold_confusion_matrix


mean_confusion_matrix = sum_confusion_matrix / k


plt.figure(figsize=(12.8,6))
sns.heatmap(mean_confusion_matrix, annot=True, cmap="Blues", fmt="g")
plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')

plt.show()

scores = cross_val_score(model, X, np.ravel(y,order='C'), cv=10)
average_score = scores.mean()
print(f"Average score: {average_score} +/- {np.std(scores)}")